{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "* pytorch의 tensor를 통해 3차원 배열 이상의 고차원 데이터를 다룸. - Numpy 배열과 매우 유사\n",
    "* GPU 연동을 통한 딥러닝 모델 학습 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device : mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('mps')\n",
    "print(f'device : {device}')\n",
    "\n",
    "# 일반적인 Nvidia GPU를 활용할 경우에는 GPU 가속화를 위해 cuda에 할당하지만\n",
    "# Apple M1 에서는 Metal(MPS)으로 변경하여 사용해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GPU 사용 여부 체크\n",
    "* tensor 간 연산을 수행할 때 기본적으로 같은 장치에 있어야 함. 둘다 CPU에 있거나 GPU에 있어야 함.\n",
    "* 가능하면 연산을 수행하는 모든 텐서를 GPU에 올린 후 연산을 수행 -> 보다 더 시간적으로 효율적\n",
    "* 딥러닝 모델에 넣는 데이터는 기본적으로 tensor 형태임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = [\n",
    "    [1,2],\n",
    "    [3,4],\n",
    "]\n",
    "\n",
    "x = torch.tensor(data)\n",
    "print(x.is_mps)\n",
    "\n",
    "x = x.to(device) # move to GPU\n",
    "print(x.is_mps)\n",
    "\n",
    "x = x.cpu() # move to CPU\n",
    "print(x.is_mps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 서로 다른 device에 있는 tensor간의 연산은 수행할 수 없음 -> 오류 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MPS device does not support mm for non-float inputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/dael/Desktop/ml_study/ml-framework-study/pytorch/pytorch-start.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dael/Desktop/ml_study/ml-framework-study/pytorch/pytorch-start.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# tensor on CPU\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dael/Desktop/ml_study/ml-framework-study/pytorch/pytorch-start.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m b \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dael/Desktop/ml_study/ml-framework-study/pytorch/pytorch-start.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     [\u001b[39m5\u001b[39m,\u001b[39m6\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dael/Desktop/ml_study/ml-framework-study/pytorch/pytorch-start.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     [\u001b[39m7\u001b[39m,\u001b[39m8\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dael/Desktop/ml_study/ml-framework-study/pytorch/pytorch-start.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m ])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/dael/Desktop/ml_study/ml-framework-study/pytorch/pytorch-start.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39;49mmatmul(a,b))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS device does not support mm for non-float inputs"
     ]
    }
   ],
   "source": [
    "# tensor on GPU\n",
    "a = torch.tensor([\n",
    "    [1,1],\n",
    "    [2,2]\n",
    "]).to(device)\n",
    "\n",
    "# tensor on CPU\n",
    "b = torch.tensor([\n",
    "    [5,6],\n",
    "    [7,8]\n",
    "])\n",
    "\n",
    "print(torch.matmul(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12, 14],\n",
      "        [24, 28]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.matmul(a.cpu(), b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tensor 기능\n",
    "* tensor는 기본적으로 다차원 배열을 처리하기에 적합한 자료구조이다.\n",
    "* 딥러닝 모델을 학습하고 데이터를 불러올 때 데이터를 처리하기 적합하다.\n",
    "* 자동 미분 기능을 제공한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. 텐서 속성\n",
    "* 텐서의 기본 속성은 다음과 같다\n",
    "  * 모양(shape)\n",
    "  * 자료형(data type)\n",
    "  * 저장된 장치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4852, 0.0151, 0.2299, 0.9312, 0.3023],\n",
      "        [0.4836, 0.2959, 0.1317, 0.3078, 0.2587],\n",
      "        [0.3409, 0.5179, 0.9627, 0.4827, 0.5240],\n",
      "        [0.1211, 0.9758, 0.1691, 0.9993, 0.7896]])\n",
      "tensor shape : torch.Size([4, 5])\n",
      "tensor data type : torch.float32\n",
      "tensor device : cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(4,5)\n",
    "\n",
    "print(tensor)\n",
    "\n",
    "# tensor의 크기를 확인할 수 있음 4 * 5 tensor 행렬\n",
    "print(f'tensor shape : {tensor.shape}') \n",
    "\n",
    "# tensor의 자료형을 확인할 수 있음 float32\n",
    "print(f'tensor data type : {tensor.dtype}')\n",
    "\n",
    "# tensor의 장치를 확인할 수 있음 cpu\n",
    "print(f'tensor device : {tensor.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. 텐서 초기화\n",
    "* 리스트 데이터에서 직접 tensor를 초기화 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 5],\n",
      "        [3, 7]])\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    [2, 5],\n",
    "    [3, 7],\n",
    "]\n",
    "\n",
    "x = torch.tensor(data)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Numpy 배열에서 tensor를 초기화하는 것도 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n",
      "<class 'numpy.ndarray'>\n",
      "tensor([50])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([3])\n",
    "b = torch.tensor([2])\n",
    "\n",
    "c = (a+b).numpy()\n",
    "print(c)\n",
    "print(type(c))\n",
    "\n",
    "res = c * 10\n",
    "tensor = torch.from_numpy(res)\n",
    "print(tensor)\n",
    "print(type(tensor))\n",
    "\n",
    "# numpy()를 통해서 numpy 배열로 변환할 할 수 있고, 반대로 from_numpy()를 통해서 tensor로 변환할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. 다른 텐서로부터 텐서 초기화하기\n",
    "* 다른 텐서의 정보를 토대로 텐서를 초기화할 수 있다.\n",
    "* 텐서의 속성 : 모양(shape), 자료형 (data type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.9919, 0.9293],\n",
      "        [0.9922, 0.7243]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([\n",
    "    [9, 2],\n",
    "    [5, 3]\n",
    "])\n",
    "\n",
    "# x와 같은 shape와 자료형을 가지지만, 모든 원소가 1인 텐서 생성\n",
    "x_ones = torch.ones_like(x)\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "# x와 같은 shape와 자료형을 가지지만, 자료형은 float32이고, 값은 랜덤인 텐서 생성\n",
    "x_rand = torch.rand_like(x, dtype=torch.float32)\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dael",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

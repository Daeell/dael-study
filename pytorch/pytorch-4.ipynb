{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 텐서의 연산과 함수\n",
    "\n",
    "## 4-1. 텐서의 연산\n",
    "* 텐서에 대하여 사칙 연산 등 기본적인 연산을 수행할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8, 10],\n",
      "        [12, 14]])\n",
      "tensor([[-6, -6],\n",
      "        [-6, -6]])\n",
      "tensor([[ 7, 16],\n",
      "        [27, 40]])\n",
      "tensor([[0.1429, 0.2500],\n",
      "        [0.3333, 0.4000]])\n"
     ]
    }
   ],
   "source": [
    "# 같은 크기를 가진 2개의 텐서에 대한 사칙연산 가능\n",
    "# 기본적으로 요소별 연산을 진행함\n",
    "\n",
    "a = torch.tensor([\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "])\n",
    "\n",
    "b = torch.tensor([\n",
    "    [7,8],\n",
    "    [9,10]\n",
    "])\n",
    "\n",
    "print(a+b)\n",
    "print(a-b)\n",
    "print(a*b)\n",
    "print(a/b)\n",
    "# 연산 시 요소별 연산 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 또한 tensor 행렬 간 곱을 수행할 수도 있다.\n",
    "* 행렬 곱은 딥러닝 분야에서 매우 많이 수행된다.\n",
    "* 따라서 이에 대한 분명한 이해가 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[58, 60],\n",
      "        [32, 34]])\n",
      "tensor([[58, 60],\n",
      "        [32, 34]])\n",
      "tensor([[58, 60],\n",
      "        [32, 34]])\n"
     ]
    }
   ],
   "source": [
    "# 행렬 간의 곱 수행 \n",
    "# 행렬 곱 연산 순서는 다음과 같다\n",
    "# 두 행렬 a의 열 개수와 행렬 b의 행 개수가 같아야 한다\n",
    "# 행렬 a의 제 i행의 각 성분과 행렬 b의 각 j열의 각 성분을 순서대로 곱하여 더한 것을 \n",
    "# (i,j) 성분으로 하는 행렬을 두 행렬 a와 b의 곱이라 한다.\n",
    "\n",
    "a = torch.tensor([\n",
    "    [5,4],\n",
    "    [3,2]\n",
    "])\n",
    "\n",
    "b = torch.tensor([\n",
    "    [6,8],\n",
    "    [7,5]\n",
    "])\n",
    "\n",
    "\n",
    "print(a.matmul(b)) \n",
    "print(torch.mm(a,b))\n",
    "print(torch.matmul(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2. 텐서의 평균 함수\n",
    "* 텐서의 평균을 계산할 수 있다 - mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 2, 1, 4],\n",
      "        [7, 5, 6, 8]])\n",
      "tensor(4.5000)\n",
      "tensor([5.0000, 3.5000, 3.5000, 6.0000])\n",
      "tensor([2.5000, 6.5000])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([\n",
    "    [3,2,1,4],\n",
    "    [7,5,6,8],\n",
    "])\n",
    "\n",
    "print(a)\n",
    "print(a.mean(dtype=torch.float32)) # 평균\n",
    "print(a.mean(dim=0, dtype=torch.float32)) # 열 기준 평균 (세로)\n",
    "print(a.mean(dim=1, dtype=torch.float32)) # 행 기준 평균 (가로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 2, 1, 4],\n",
      "        [1, 2, 3, 4]])\n",
      "tensor(20)\n",
      "tensor([4, 4, 4, 8])\n",
      "tensor([10, 10])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([\n",
    "    [3,2,1,4],\n",
    "    [1,2,3,4],\n",
    "])\n",
    "\n",
    "print(a)\n",
    "print(a.sum()) # 전체 합\n",
    "print(a.sum(dim=0)) # 열 합\n",
    "print(a.sum(dim=1)) # 행 합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-4. 텐서의 최대 함수\n",
    "* max() 함수는 원소의 최댓값을 반환한다.\n",
    "* argmax() 함수는 가장 큰 원소(최댓값)의 인덱스를 반환한다.\n",
    "* indices를 보면 열(dim=0)이나 행(dim=1)기준으로 어떤 인덱스에서 최댓값이 위치하는지 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor(6)\n",
      "torch.return_types.max(\n",
      "values=tensor([4, 5, 6]),\n",
      "indices=tensor([1, 1, 1]))\n",
      "torch.return_types.max(\n",
      "values=tensor([3, 6]),\n",
      "indices=tensor([2, 2]))\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([\n",
    "    [1,2,3],\n",
    "    [4,5,6]\n",
    "])\n",
    "\n",
    "print(a)\n",
    "print(a.max()) # 전체 원소의 최댓값\n",
    "print(a.max(dim=0)) # 각 열의 최댓값 \n",
    "print(a.max(dim=1)) # 각 행의 최댓값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([\n",
    "    [4,1,2,3],\n",
    "    [6,8,5,7]\n",
    "])\n",
    "\n",
    "print(a.argmax()) # 최대값의 인덱스\n",
    "print(a.argmax(dim=0)) # 열 단위로 최대값의 인덱스\n",
    "# 4,6 중에 6이 크고 (세로 기준 1번째 인덱스), 1,8 중에 8이 크고 (세로 기준 1번째 인덱스) ...\n",
    "print(a.argmax(dim=1)) # 행 단위로 최대값의 인덱스\n",
    "# 4,1,2,3 중에 4가 크고 (가로 기준 0번째 인덱스), 6,8,5,7 중에 8이 크고 (세로 기준 1번째 인덱스)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-5. 텐서의 차원 줄이기 혹은 늘리기\n",
    "* squeeze() 함수는 크기가 1인 차원을 제거해 준다.\n",
    "    * 주의할 점은 batch가 1일 때 batch차원도 제거하는 경우가 발생함\n",
    "    * validation 단계에서 오류가 발생할 수 있으므로 주의해서 사용\n",
    "* unsqueeze() 함수는 크기가 1인 차원을 추가하는 함수이다.\n",
    "    * batch 차원을 추가하기 위한 목적으로 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n",
      "tensor([[[4, 1, 2, 3],\n",
      "         [6, 8, 5, 7]]])\n",
      "torch.Size([1, 2, 4])\n",
      "tensor([[[[4],\n",
      "          [1],\n",
      "          [2],\n",
      "          [3]],\n",
      "\n",
      "         [[6],\n",
      "          [8],\n",
      "          [5],\n",
      "          [7]]]])\n",
      "torch.Size([1, 2, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([\n",
    "    [4,1,2,3],\n",
    "    [6,8,5,7]\n",
    "])\n",
    "\n",
    "print(a.shape) # 2 * 4 행렬\n",
    "\n",
    "# 첫 번째 축에 차원 추가\n",
    "a = a.unsqueeze(0)\n",
    "print(a)\n",
    "print(a.shape) # 1 * 2 * 4 행렬\n",
    "\n",
    "# 네 번째 축에 차원 추가\n",
    "a = a.unsqueeze(3)\n",
    "print(a)\n",
    "print(a.shape) # 1 * 2 * 4 * 1 행렬\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드 추가 설명 - tensor 차원의 개념\n",
    "\n",
    "- 원래 a 행렬은 2x4 행렬이다.\n",
    "\n",
    "```\n",
    "[\n",
    "  [4, 1, 2, 3],\n",
    "  [6, 8, 5, 7]\n",
    "]\n",
    "```\n",
    "\n",
    "- .unsqueeze(0)를 호출하면, 이 행렬은 3차원 텐서로 변환되며, 새로운 차원은 다른 모든 차원의 \"상자\" 또는 \"컨테이너\" 역할을 한다. 새로운 텐서는 다음과 같이 보인다.\n",
    "\n",
    "```\n",
    "[\n",
    "  [\n",
    "    [4, 1, 2, 3],\n",
    "    [6, 8, 5, 7]\n",
    "  ]\n",
    "]\n",
    "```\n",
    "\n",
    "- 이제 이 텐서는 1x2x4 텐서다. 1은 새로운 차원의 크기이다. 여기에는 단 하나의 원소 - 원래의 2x4 행렬만 존재한다.\n",
    "\n",
    "```\n",
    "원래 행렬:\n",
    "2D (2x4)\n",
    "+---+---+---+---+\n",
    "| 4 | 1 | 2 | 3 |\n",
    "+---+---+---+---+\n",
    "| 6 | 8 | 5 | 7 |\n",
    "+---+---+---+---+\n",
    "\n",
    ".unsqueeze(0) 후:\n",
    "3D (1x2x4)\n",
    "+---------------+\n",
    "| +---+---+---+---+ |\n",
    "| | 4 | 1 | 2 | 3 | |\n",
    "| +---+---+---+---+ |\n",
    "| | 6 | 8 | 5 | 7 | |\n",
    "| +---+---+---+---+ |\n",
    "+---------------+\n",
    "```\n",
    "\n",
    "- .unsqueeze(3)을 호출하면 각 요소가 하나의 배열로 감싸지면서 1x2x4x1 배열이 된다.\n",
    "\n",
    "```\n",
    "[\n",
    "  [\n",
    "    [[4], [1], [2], [3]],\n",
    "    [[6], [8], [5], [7]]\n",
    "  ]\n",
    "]\n",
    "```\n",
    "\n",
    "```\n",
    ".unsqueeze(3) 후:\n",
    "4D (1x2x4x1)\n",
    "+---------------------------------+\n",
    "| +---------+         +---------+ |\n",
    "| | +---+   |         | +---+   | |\n",
    "| | | 4 |   |         | | 6 |   | |\n",
    "| | +---+   |         | +---+   | |\n",
    "| | +---+   |         | +---+   | |\n",
    "| | | 1 |   |         | | 8 |   | |\n",
    "| | +---+   |         | +---+   | |\n",
    "| | +---+   |         | +---+   | |\n",
    "| | | 2 |   |         | | 5 |   | |\n",
    "| | +---+   |         | +---+   | |\n",
    "| | +---+   |         | +---+   | |\n",
    "| | | 3 |   |         | | 7 |   | |\n",
    "| | +---+   |         | +---+   | |\n",
    "| +---------+         +---------+ |\n",
    "+---------------------------------+\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dael",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

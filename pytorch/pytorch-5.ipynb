{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 자동 미분과 기울기 (gradient)\n",
    "\n",
    "* Pytorch에서는 연산에 대해서 기본적으로 자동 미분(auto_grad)을 수행할 수 있다\n",
    "* requires_grad 속성을 True로 설정하면, 이에 대한 모든 연산을 추적한다.\n",
    "* 계산이 끝났을 때 .backward()를 호출하여, 자동으로 모든 기울기(gradient)를 계산할 수 있다.\n",
    "* 이를 통해 tensor에 대한 기울기(gradient)는 .grad 속성에 누적된다.\n",
    "* Function class는 autograd 구현에 있어 중요하다.\n",
    "* 텐서와 function은 상호 연결되어 모든 연산 과정을 부호화하여 순환하지 않는 반복 그래프를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8., 10.], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x107647490>\n",
      "tensor(9., grad_fn=<MeanBackward0>)\n",
      "<MeanBackward0 object at 0x107645990>\n",
      "tensor([0.5000, 0.5000])\n",
      "tensor([0.5000, 0.5000])\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rj/b_cmk_pn69n575nzf14srndh0000gn/T/ipykernel_45653/1046591888.py:20: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1695391816234/work/build/aten/src/ATen/core/TensorBody.h:494.)\n",
      "  print(z.grad) # None\n"
     ]
    }
   ],
   "source": [
    "# requires_grad를 설정할 때만 기울기를 추적한다.\n",
    "x = torch.tensor([3.0,4.0], requires_grad=True)\n",
    "y = torch.tensor([5.0,6.0], requires_grad=True)\n",
    "z = x + y\n",
    "\n",
    "# 각각의 tensor는 Tensor를 생성한 function을 참조하는 grad.fn 속성을 갖고 있다.\n",
    "\n",
    "print(z) # [8.0, 10.0] z는 연산의 결과 생성되었으므로 grad_fn 속성을 갖는다\n",
    "print(z.grad_fn) # AddBackward0 - 더하기\n",
    "\n",
    "out = z.mean()\n",
    "print(out) # 9\n",
    "print(out.grad_fn) # MeanBackward0 - 평균\n",
    "\n",
    "out.backward() # 기울기 계산\n",
    "# out은 하나의 scalar이므로 기울기는 항상 1이다.\n",
    "print(x.grad) \n",
    "print(y.grad)\n",
    "# grad = 0.5인 것은 각 leaf variable이 1만큼 바뀌면 out은 0.5만큼 바뀐다는 것을 의미한다.\n",
    "print(z.grad) # None \n",
    "# leaf variable(초기 입력으로 들어가는 변수)에 대해서만 gradient 추적이 가능하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 일반적으로 모델을 학습할 때는 기울기(gradient)를 추적한다.\n",
    "* 하지만 학습된 모델을 사용할 때에는 파라미터를 업데이트하지 않으므로 기울기를 추적하지 않는 것이 일반적이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "tmp = torch.tensor([2.0,3.0], requires_grad=True)\n",
    "print(tmp.requires_grad) # True, tmp 텐서에 대해 gradient 추적\n",
    "print((tmp ** 2).requires_grad) # True, 텐서 연산 결과에 대해 gradient 추적\n",
    "\n",
    "# with torch.no_grad():로 코드 블럭을 감싸서 tensor의 기록을 추적하는 autograd를 중지할 수 있다.\n",
    "# 기울기 추적을 하지 않기 때문에 계산 속도가 더 빠르다.\n",
    "with torch.no_grad():\n",
    "    tmp = torch.tensor([2.0,3.0], requires_grad=True)\n",
    "    print(tmp.requires_grad) # True, 하지만 해당 코드 블럭 내에서는 무시됨\n",
    "    print((tmp ** 2).requires_grad) # False, 이 코드 블럭 내에서는 gradient가 추적되지 않음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dael",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
